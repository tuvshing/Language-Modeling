{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FuO82RTBftK"
      },
      "source": [
        "# Language Modeling\n",
        "\n",
        "Generate text using a trigram language model.\n",
        "\n",
        "Go to https://drive.google.com/drive/folders/1JqAnRSkJqAWlHQRR8tN9is3vKZ-4VKWM?usp=sharing and click add shortcut to drive. This will add the data required for this problem set to your Google drive.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1LqHisiziX8Ri94Xs6Cv8mhx6vivFM3kS\" alt=\"Drawing\" height=\"300\"/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtZEcHthBeXz"
      },
      "source": [
        "Run the below code snippet. It will generate a URL which generates an authorization code.* Enter it below to give Colab access to your Google drive. \n",
        "\n",
        "*Copy function may not work. If so, manually copy the authorization code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KW-dce7oJlyr",
        "outputId": "6275ea1b-ceb7-42ff-c3c3-a3be0cb3723b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2Y7I_9lPoZS"
      },
      "source": [
        "Let's load the trigrams first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZMOmElPSPHk"
      },
      "outputs": [],
      "source": [
        "from math import log\n",
        "\n",
        "bigram_prefix_to_trigram = {}\n",
        "bigram_prefix_to_trigram_weights = {}\n",
        "\n",
        "lines = open(\"/content/drive/My Drive/nl2ds/tweets/covid-tweets-2020-08-10-2020-08-21.trigrams.txt\").readlines()\n",
        "for line in lines:\n",
        "  word1, word2, word3, count = line.strip().split()\n",
        "  if (word1, word2) not in bigram_prefix_to_trigram:\n",
        "    bigram_prefix_to_trigram[(word1, word2)] = []\n",
        "    bigram_prefix_to_trigram_weights[(word1, word2)] = []\n",
        "  bigram_prefix_to_trigram[(word1, word2)].append(word3)\n",
        "  bigram_prefix_to_trigram_weights[(word1, word2)].append(int(count))\n",
        "\n",
        "# freeup memory\n",
        "lines = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X48i3rarPzd8"
      },
      "source": [
        "### 1: Retrieving top next words\n",
        "\n",
        "Retrieving the top next words and their probability given a bigram prefix.\n",
        "\n",
        "For the following prefixes **word1=middle, word2=of, and n=10**, the output is:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYhal88xSYow",
        "outputId": "2f95ba52-f106-4708-83f2-a0b5d55fb51a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a 0.807981220657277\n",
            "the 0.06948356807511737\n",
            "pandemic 0.023943661971830985\n",
            "this 0.016901408450704224\n",
            "an 0.0107981220657277\n",
            "covid 0.009389671361502348\n",
            "nowhere 0.008450704225352112\n",
            "it 0.004694835680751174\n",
            "lockdown 0.002347417840375587\n",
            "summer 0.002347417840375587\n"
          ]
        }
      ],
      "source": [
        "def top_next_word(word1, word2, n=10):\n",
        "  next_words = []\n",
        "  probs = []\n",
        "  a = bigram_prefix_to_trigram[(word1, word2)]\n",
        "  s = sum(bigram_prefix_to_trigram_weights[(word1, word2)])\n",
        "  if len(a) < n:\n",
        "    n = len(a)\n",
        "  for i in range(n):\n",
        "    next_words.append(bigram_prefix_to_trigram[(word1, word2)][i])\n",
        "    probs.append(bigram_prefix_to_trigram_weights[(word1, word2)][i] / s)\n",
        "  return next_words, probs\n",
        "\n",
        "next_words, probs = top_next_word(\"middle\", \"of\", 10)\n",
        "for word, prob in zip(next_words, probs):\n",
        "  print(word, prob)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gok10i2dSHXB"
      },
      "source": [
        "## 2: Sampling n words\n",
        "\n",
        "Sampling the next n words given a bigram prefix without repetition using the probablity distribution defined by the frequency counts.\n",
        "\n",
        "\n",
        "For the following prefixes **word1=middle, word2=of, and n=10**, the output could be as follows:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OzYJoYfUaom",
        "outputId": "241c1e7a-c038-4e14-a32d-9cac6694f2e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a 0.807981220657277\n",
            "this 0.016901408450704224\n",
            "the 0.06948356807511737\n",
            "pandemic 0.023943661971830985\n",
            "covid 0.009389671361502348\n",
            "nowhere 0.008450704225352112\n",
            "them 0.00046948356807511736\n",
            "an 0.0107981220657277\n",
            "summer 0.002347417840375587\n",
            "<EOS> 0.0009389671361502347\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "def sample_next_word(word1, word2, n=10):\n",
        "  a = bigram_prefix_to_trigram[(word1, word2)]\n",
        "  weights = bigram_prefix_to_trigram_weights[(word1, word2)]\n",
        "  probs = []\n",
        "  next_probs = []\n",
        "  s = sum(weights)\n",
        "  l = len(a)\n",
        "  for i in range(l):\n",
        "    probs.append(weights[i] / s)  \n",
        "  if l < n:\n",
        "    n = l\n",
        "  next_words = np.random.choice(a, size=n, replace=False, p=probs)\n",
        "  for i in next_words:\n",
        "    next_probs.append(probs[a.index(i)])\n",
        "  next_words = next_words.tolist()\n",
        "  return next_words, next_probs\n",
        "\n",
        "next_words, probs = sample_next_word(\"middle\", \"of\", 10)\n",
        "for word, prob in zip(next_words, probs):\n",
        "  print(word, prob)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyYenU8H-fIR"
      },
      "source": [
        "## 3: Generate sentences starting with a prefix\n",
        "\n",
        "Generates n-sentences starting with a given sentence prefix. Uses [beam search](https://en.wikipedia.org/wiki/Beam_search) to generate multiple sentences.\n",
        "\n",
        "Methods are:\n",
        "\n",
        "* `word_generator=top_next_word`, `beam=10` and prefix is `<BOS1> <BOS2> trump`\n",
        "\n",
        "* `word_generator=top_next_word`, `beam=10` and prefix is `<BOS1> <BOS2> biden`\n",
        "\n",
        "* `word_generator=sample_next_word`, `beam=10` and prefix is `<BOS1> <BOS2> trump`\n",
        "\n",
        "* `word_generator=sample_next_word`, `beam=10` and prefix is `<BOS1> <BOS2> biden`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40kW0joweXFO",
        "outputId": "78ad1dda-e7a9-4cf1-f824-18165fe9f167"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<BOS1> <BOS2> trump eyes new unproven coronavirus treatment URL <EOS> 0.00021893147502903603\n",
            "<BOS1> <BOS2> trump eyes new unproven coronavirus cure URL <EOS> 0.0001719607222046247\n",
            "<BOS1> <BOS2> trump eyes new unproven virus cure promoted by mypillow ceo over unproven therapeutic URL <EOS> 9.773272077557522e-05\n",
            "<BOS1> <BOS2> trump eyes new unproven coronavirus therapeutic mypillow creator over unproven therapeutic URL <EOS> 8.212549111137046e-05\n",
            "<BOS1> <BOS2> trump eyes new unproven virus cure promoted by mypillow ceo over unproven therapeutic URL via @USER <EOS> 7.432226908194607e-06\n",
            "<BOS1> <BOS2> trump eyes new unproven virus cure promoted by mypillow ceo over unproven and dangerous <EOS> 5.61685494684627e-06\n",
            "<BOS1> <BOS2> trump eyes new unproven virus cure promoted by mypillow ceo over unproven and dangerous covid-19 treatment URL <EOS> 5.235550241426875e-06\n",
            "<BOS1> <BOS2> trump eyes new unproven virus cure promoted by ben carson and mypillow founder and ceo of mypillow URL <EOS> 2.1484173056680325e-06\n",
            "<BOS1> <BOS2> trump eyes new unproven virus cure promoted by ben carson and mypillow founder and ceo mike lindell a big deal <EOS> 1.4263568494891567e-08\n",
            "<BOS1> <BOS2> trump eyes new unproven virus cure promoted by ben carson and mypillow founder and ceo mike lindell a big deal and the pandemic <EOS> 4.890594996717161e-12\n",
            "#########################\n",
            "\n",
            "<BOS1> <BOS2> biden calls for a 30 bonus URL #cashgem #cashappfriday #stayathome <EOS> 0.0002495268686322749\n",
            "<BOS1> <BOS2> biden says all u.s. governors should mandate masks <EOS> 1.6894510541025754e-05\n",
            "<BOS1> <BOS2> biden says all u.s. governors question cost of a pandemic <EOS> 8.777606198953028e-07\n",
            "<BOS1> <BOS2> biden says all u.s. governors should mandate mandatory mask rule URL <EOS> 6.46094976762742e-07\n",
            "<BOS1> <BOS2> biden says all u.s. governors should mandate masks and social distancing <EOS> 4.6833316176693136e-07\n",
            "<BOS1> <BOS2> biden says all u.s. governors should mandate mandatory mask wearing and social distancing <EOS> 4.380454675651422e-08\n",
            "<BOS1> <BOS2> biden says all u.s. governors should mandate mandatory mask wearing and social distancing URL <EOS> 2.2277082512658355e-08\n",
            "<BOS1> <BOS2> biden says all u.s. governors should mandate mandatory mask wearing and social distancing and wearing masks <EOS> 1.166766912614153e-10\n",
            "<BOS1> <BOS2> biden says all u.s. governors should mandate mandatory mask wearing and social distancing and wearing a mask <EOS> 1.1355525098965152e-10\n",
            "<BOS1> <BOS2> biden says all u.s. governors should mandate mandatory mask wearing and social distancing and wearing a mask and social distancing and masks are not the same time <EOS> 2.3660719518591428e-20\n",
            "#########################\n",
            "\n",
            "<BOS1> <BOS2> trump urges americans to die <EOS> 4.276844959011809e-05\n",
            "<BOS1> <BOS2> trump urges americans to wear a mask <EOS> 2.2771257098608776e-05\n",
            "<BOS1> <BOS2> trump urges americans to die from covid <EOS> 8.636521863925917e-06\n",
            "<BOS1> <BOS2> trump urges americans to wear a mask and social distancing URL <EOS> 7.317252846179007e-08\n",
            "<BOS1> <BOS2> trump urges americans to wear a mask and social distancing URL URL <EOS> 5.666730772897511e-09\n",
            "<BOS1> <BOS2> trump urges americans to wear a mask and social distance and wear a mask <EOS> 9.382824864658153e-10\n",
            "<BOS1> <BOS2> trump urges americans to wear a mask and social distance and wear a mask URL <EOS> 3.552473266045694e-10\n",
            "<BOS1> <BOS2> trump urges americans to wear a mask and social distance and wear a mask for a 30 bonus URL #cashgem #cashappfriday #stayathome <EOS> 2.0297692211895e-12\n",
            "<BOS1> <BOS2> trump urges americans to wear a mask and social distance and wear a mask for a 30 bonus URL #rewarddollars #makemoneyfromhome #stayathome <EOS> 3.029487646721147e-14\n",
            "<BOS1> <BOS2> trump urges americans to wear a mask and social distance and wear a mask for a 30 bonus URL #rewarddollars #makemoneyfromhome #stayathome sign up today for a long time ago but i ’m not sure if you do n’t have to wear a mask and social distancing and masks are not getting the virus is the only way to get back to school and the trump administration is a hoax and that ’s why i do n’t have to wear a mask <EOS> 7.54803499310846e-67\n",
            "#########################\n",
            "\n",
            "<BOS1> <BOS2> biden leads trump follows <EOS> 0.001796945193171608\n",
            "<BOS1> <BOS2> biden hires a witch URL <EOS> 0.0005775895263765884\n",
            "<BOS1> <BOS2> biden leads trump 53 to 42 go figure <EOS> 8.485574523310372e-05\n",
            "<BOS1> <BOS2> biden leads trump 53 to 42 go figure URL <EOS> 4.7585770856211104e-05\n",
            "<BOS1> <BOS2> biden leads trump 53 to 42 k just today <EOS> 8.423180592991913e-06\n",
            "<BOS1> <BOS2> biden says all u.s. governors should mandate mandatory mask wearing and social distancing <EOS> 4.380454675651422e-08\n",
            "<BOS1> <BOS2> biden leads trump 53 to 42 k just posted a picture of a pandemic <EOS> 4.896812360137646e-09\n",
            "<BOS1> <BOS2> biden leads trump 53 to 42 k just posted a video of ‘ class ’ in former soviet state — where covid is over <EOS> 8.616315133369063e-12\n",
            "<BOS1> <BOS2> biden leads trump 53 to 42 k just posted a video of ‘ class ’ in former soviet state — where covid is over i 'm inviting you all to join cashgem a site that lets you earn money with social distancing <EOS> 2.2410427138897846e-16\n",
            "<BOS1> <BOS2> biden leads trump 53 to 42 k just posted a video of ‘ class ’ in former soviet state — where covid is over i 'm inviting you all to join cashgem a site that lets you earn money with social media i just earned 84794 and you can not be able to see how it ’s not a good idea to have a lot of people who are not getting the coronavirus pandemic URL <EOS> 1.031124557226618e-45\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import heapq\n",
        "\n",
        "def generate_sentences(prefix, beam, sampler):\n",
        "  # class for Beam search using heap queue\n",
        "  class BeamTree(object):\n",
        "    def __init__(self, width):\n",
        "        self.heap = list()\n",
        "        self.width = width\n",
        "    def add(self, prob, eos, prefix, sentence):\n",
        "        heapq.heappush(self.heap, (prob, eos, prefix, sentence))\n",
        "        if len(self.heap) > self.width:\n",
        "            heapq.heappop(self.heap)\n",
        "    def get(self):\n",
        "        return self.heap\n",
        "    def __iter__(self):\n",
        "        return iter(self.heap)\n",
        "\n",
        "  prevB = BeamTree(beam)\n",
        "  terms = prefix.split()\n",
        "  # initialize heapq\n",
        "  prevB.add(1.0, False, [ terms[1], terms[2] ] , [ terms[0], terms[1], terms[2] ])\n",
        "  while True:\n",
        "    newB = BeamTree(beam)\n",
        "    for (prefix_prob, eos, prefixN, sentence) in prevB:\n",
        "      if eos == True: # if reached EOS, sentence finished\n",
        "          newB.add(prefix_prob, True, prefixN, sentence)\n",
        "      else:\n",
        "          # get next_words and next_probs from the sampler function\n",
        "          next_words, next_probs = sampler(prefixN[0], prefixN[1], 10)\n",
        "          for i in next_words:\n",
        "            if i == '<EOS>':\n",
        "              newB.add(prefix_prob*next_probs[next_words.index(i)], True, prefixN, sentence + [i])\n",
        "            else:\n",
        "              newB.add(prefix_prob*next_probs[next_words.index(i)], False, [prefixN[1]] + [i], sentence + [i])\n",
        "    \n",
        "    # check if all sentences are finished\n",
        "    isFinished = [i[1] for i in newB.get()]\n",
        "    if all(isFinished) == True: # if all sentences are finished, return the results\n",
        "      res3 = sorted([(i[3], i[0]) for i in newB.get()], key = lambda x: x[1], reverse=True)\n",
        "      res1, res2 = zip(*res3)\n",
        "      res1 = [' '.join(x) for x in res1]\n",
        "      return res1, res2\n",
        "\n",
        "    prevB = newB\n",
        "    \n",
        "sentences, probs = generate_sentences(prefix=\"<BOS1> <BOS2> trump\", beam=10, sampler=top_next_word)\n",
        "for sent, prob in zip(sentences, probs):\n",
        "  print(sent, prob)\n",
        "print(\"#########################\\n\")\n",
        "\n",
        "sentences, probs = generate_sentences(prefix=\"<BOS1> <BOS2> biden\", beam=10, sampler=top_next_word)\n",
        "for sent, prob in zip(sentences, probs):\n",
        "  print(sent, prob)\n",
        "print(\"#########################\\n\")\n",
        "\n",
        "sentences, probs = generate_sentences(prefix=\"<BOS1> <BOS2> trump\", beam=10, sampler=sample_next_word)\n",
        "for sent, prob in zip(sentences, probs):\n",
        "  print(sent, prob)\n",
        "print(\"#########################\\n\")\n",
        "\n",
        "sentences, probs = generate_sentences(prefix=\"<BOS1> <BOS2> biden\", beam=10, sampler=sample_next_word)\n",
        "for sent, prob in zip(sentences, probs):\n",
        "  print(sent, prob)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Language Modeling.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
